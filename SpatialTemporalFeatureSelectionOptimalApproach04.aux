\relax 
\citation{0813340853,2004icti.book.....M}
\citation{1985PhyD...16..285W,1994PhLA..185...77K}
\citation{9780486693873}
\citation{1451722}
\citation{Powell:1987:RBF:48424.48433,Broomhead1988MultivariableFI}
\citation{PhysRevLett.59.845}
\citation{0130607746}
\citation{1165342}
\citation{LANGKVIST201411}
\citation{doi:10.1063/1.165894,PhysRevE.51.R2709,PhysRevLett.85.2300,Parlitz2000NonlinearPO,2000PhRvL..84.1890P,Xia2006APF,ENV:ENV2266,covas2016,ENV:ENV2456}
\citation{covaspeixinhojoao,2017arXiv170805094M,2017arXiv171100636M,2017arXiv171110566R,2017arXiv171110561R,2017arXiv171009668L,2018JCoPh.357..125R,2018arXiv180106637R}
\citation{9780521857291}
\citation{9780198512905}
\citation{1851RSPT..141..123S,1852RSPT..142..103S,1979P&SS...27.1001S,1983SoPh...89..195E,1965P&SS...13....9P,2000AdSpR..26...27W,2003A&AT...22..861B,2005GeoRL..3221106S,2005SpWea...3.8C01K,2006GMS...165..367T,2006GeoRL..3318101H,2009SunGe...4...55C,2011SpWea...9.6001C,2013EGUGA..1510865W,2015SpWea..13..524S}
\citation{1985PhLA..107..101G}
\citation{Waibel:1990:PRU:108235.108263,luk2000study,Frank2001,OH2002249,1009-1963-12-6-304,inputlayer}
\citation{covas2016,covaspeixinhojoao}
\citation{1981LNM...898..366T}
\citation{key1503303m}
\citation{1981LNM...898..366T,1981LNM...898..230M}
\citation{1991JSP....65..579S}
\citation{Fraser86,abarbanel1997analysis,opac-b1092652}
\citation{1992PhRvA..45.3403K}
\citation{1992PhRvA..45.7058M,1993RvMP...65.1331A,1996PhT....49k..86A,abarbanel1997analysis}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\citation{McCulloch1943}
\citation{2017arXiv170805094M,2017arXiv171100636M,2017arXiv171205293C,ghaderi2017deepforecast}
\citation{annunziato,Gkana201579,Zachilas2015,Sun2010109,HUANG20108590,298224,Frank2001,1998GeoRL..25..457K,BUHAMRA2003805,chandra2012cooperative,DBLP:journals/corr/MaslennikovaB14,sauter2010spatio,JiangS11,inputlayer,1997IJMPC...8.1345K,1009-1963-12-6-304,Verdes2000,1996SoPh..168..423F,2007AdG....10...67L,Chandra:2012:CCE:2181341.2181747,raios,maass2003mathematical}
\citation{0305-4470-28-12-012,1995ApJ...444..916C,1998GeoRL..25..457K,Zachilas2015,Chandra:2012:CCE:2181341.2181747,Gkana201579,raios}
\citation{Simon:2007:HDS:1230147.1230294}
\citation{articleRagulskis}
\citation{Xia2006APF}
\citation{Parlitz2000NonlinearPO}
\citation{Fraser86,abarbanel1997analysis,opac-b1092652}
\citation{key1503303m}
\citation{1981LNM...898..366T,1981LNM...898..230M}
\citation{1991JSP....65..579S}
\citation{1992PhRvA..45.3403K}
\citation{1992PhRvA..45.7058M,1993RvMP...65.1331A,1996PhT....49k..86A,abarbanel1997analysis}
\citation{Waibel:1990:PRU:108235.108263}
\citation{10.1007/BFb0006203,1986Natur.323..533R,58337}
\citation{Parlitz2000NonlinearPO}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-A}}Neural networks for time-series forecasting}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-B}}Neural networks for spatial-temporal forecasting}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {I-C}}Input layer architecture for neural networks for spatial-temporal forecasting}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Forecasting method illustration. The neural network is made of an input layer, one or more hidden layer(s) and one output layer. In this article, we use only one hidden layer and the output layer is made of a single neuron. Each input pattern $x(i)$ is sent to the input layer, then each of the hidden neurons values is calculated from the sum of the product of the weights by the inputs $\DOTSI \sumop \slimits@ w(i,j) x(i)$ and passed via the activation function. Then the output is made by the product of the second set of weights times the hidden node values $\DOTSI \sumop \slimits@ w'(i,j) y(i)$ again passed to another (or the same) activation function. Each input pattern $x(i)$ is actually a matrix constructed using an embedding space of spatial and temporal delays, calculated from the actual physical spatial-temporal data values $s(n,m)$. After many randomly chosen input patterns are passed via the neural network, the weights hopefully converge to an optimal training value.}}{2}}
\newlabel{architecture}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Neural Network architecture}{2}}
\citation{Wang04imagequality}
\citation{covas2016,covaspeixinhojoao}
\citation{2015arXiv150100092D}
\citation{2018arXiv180208369Z}
\citation{Wang04imagequality,2009ISPM...26...98W,2012ITIP...21.1488B}
\citation{1555956}
\citation{Frank2001}
\citation{Fraser86,abarbanel1997analysis,opac-b1092652}
\citation{1992PhRvA..45.3403K,1992PhRvA..45.7058M,1993RvMP...65.1331A,1996PhT....49k..86A,abarbanel1997analysis}
\citation{2001Chaos..11..404C}
\citation{2001cfsm.book.....B}
\newlabel{embedding}{{1}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Monte Carlo results}{3}}
\citation{covaspeixinhojoao}
\citation{1990EOSTr..71..677K,1991PhDT.......158W,Weigend92HubermanRumelhart,1993AdSpR..13..447M,1995JGR...10021735M,1994VA.....38..351C,0305-4470-28-12-012,1995ApJ...444..916C,Koskela96timeseries,1996SoPh..168..423F,1996AnGeo..14...20F,1996ITNN....7..501P,1998GeoRL..25..457K,1998JGR...10329733C,1998NewAR..42..343C,Verdes2000,2004SoPh..221..167V,2001GMS...125..201L,2002PhRvE..66f6701S,2004SoPh..224..247M,2005JASTP..67..595G,2004SPIE.5497..542A,2005MmSAI..76.1030Q,2005SoPh..227..177A,2006JASTP..68.2061M,2007SoPh..243..253Q,2013Ap&SS.344....5A,xie2006hybrid,2006SunGe...1a...8M,2007IJMPC..18.1839E,1997SPIE.3077..116P,2006AGUFMSH21A0315L,2008cosp...37.3467W,gang2007sunspot,2009JASTP..71..569U,2010BAAA...53..241F,1999BAAA...43...23P,2011RAA....11..491A,2010cosp...38.2153A,2011CRGeo.343..433C,JiangS11,2012cosp...39.1194M,Chandra:2012:CCE:2181341.2181747,park2009prediction,kim2010sunspot,moghaddam2013sunspot,2012EPJP..127...43C,liu2012sunspot,Gkana201579,DBLP:conf/ijcnn/ParsapoorBS15,DBLP:conf/aaai/ParsapoorBS15,raios}
\citation{covaspeixinhojoao}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Forecasting method illustration. One constructs an embedding space using space and time delays, then assemble randomly positioned grid input patterns within the training set to pass to the neural network (in this figure we show 3 randomly selected input patterns). The input is a $(2 I+1)(J+1)$ vector ${\bf  x}(s^n_m)$ and the target (output) to train the network is the value $s^{n+1}_{m}$. After training with a sequence of patterns $p(i), p(i+1), p(i+2), \ldots  $ then the patterns adjacent to the forecast set are used to calculate the outputs to compare against the forecast. To forecast the $n+2$ slice we concatenate the previously predicted $n+1$ and progress accordingly.}}{4}}
\newlabel{NeuralNetwork}{{2}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Our main conjecture. For a infinite noiseless training set, the SSIM approaches $\textnormal  {SSIM} \to 1$. For real data sets, there is a dispersion of the SSIM versus some reasonable metric constructed to represent the distance between any architecture (e.g.\ $d_e\sqrt  {(I-I^*)^2+(J-J^*)^2+(K-K^*)^2+(L-L^*)^2}$). }}{4}}
\newlabel{conjecture}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Sunspot data - a physical system example}{4}}
\citation{1989PThPS..99..263K,1989JSP....54.1489M,9780471937418}
\citation{2000PhRvL..84.1890P,Parlitz2000NonlinearPO}
\citation{articleLorenz96}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Monte Carlo simulation of different architectures of the input layer for the neural network forecast for the sunspot data. It shows the structural similarity (SSIM) against how far (in an Euclidean space metric) the particular parameters of a particular run were from the supposely optimal architecture parameters (red dot).}}{5}}
\newlabel{MonteCarloSSIMversusParameterMetricDistance}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Coupled H\'{e}non maps - a discrete-time dynamical system}{5}}
\newlabel{henon}{{2}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Monte Carlo simulation of different architectures of the input layer for the neural network forecast for a series of 100 coupled H\'{e}non maps. It shows the structural similarity (SSIM) against how far (in a Euclidean space metric) the particular parameters of a particular run was from the supposedly optimal architecture parameters (red dot). The green line (trendline) seems to show that as the parameters of a randomly chosen architecture get close to the supposedly optimal architecture ones, the SSIM converges to what seems to be the best possible forecast value given the limited dataset.}}{5}}
\newlabel{MonteCarloSSIMversusParameterMetricDistance100HenonCoupledMaps}{{5}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Coupled Ordinary Differential Equations - Lorenz-96 model}{5}}
\newlabel{lorenz96equations}{{3}{5}}
\citation{1976PThPh..55..356K,1977AcAau...4.1177S}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Monte Carlo simulation of different architectures of the input layer for the neural network forecast for the 40-ODE Lorenz 96 system. It shows the structural similarity (SSIM) against how far (in a Euclidean space metric) the particular parameters of a particular run was from the supposedly optimal architecture parameters (red dot). The green line (trendline) seems to show that as the parameters of a randomly chosen architecture get close to the supposedly optimal architecture ones, the SSIM converges to what seems to be the best possible forecast value given the limited (and noisy) dataset.}}{6}}
\newlabel{MonteCarloSSIMversusParameterMetricDistanceLorenz96}{{6}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Partial Differential Equations - Kuramoto-Sivashinsky model}{6}}
\newlabel{kuramotoSivashinskyequation}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Monte Carlo simulation of different architectures of the input layer for the neural network forecast for Kuramoto-Sivashinsky with $L=22$ system. It shows the structural similarity (SSIM) against how far (in a Euclidean space metric) the particular parameters of a particular run was from the supposedly optimal architecture parameters (red dot). The green line (trendline) seems to show that as the parameters of a randomly chosen architecture get close to the supposedly optimal architecture ones, the SSIM converges to what seems to be the best possible forecast value given the limited (and noisy) dataset.}}{6}}
\newlabel{MonteCarloSSIMversusParameterMetricDistanceKS_L=22}{{7}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Conclusion}{6}}
\citation{Wikle:2015:MPS:3160227.3160234}
\bibstyle{IEEEtran}
\bibdata{IEEEabrv,eurico}
\bibcite{0813340853}{1}
\bibcite{2004icti.book.....M}{2}
\bibcite{1985PhyD...16..285W}{3}
\bibcite{1994PhLA..185...77K}{4}
\bibcite{9780486693873}{5}
\bibcite{1451722}{6}
\bibcite{Powell:1987:RBF:48424.48433}{7}
\bibcite{Broomhead1988MultivariableFI}{8}
\bibcite{PhysRevLett.59.845}{9}
\bibcite{0130607746}{10}
\bibcite{1165342}{11}
\bibcite{LANGKVIST201411}{12}
\bibcite{doi:10.1063/1.165894}{13}
\bibcite{PhysRevE.51.R2709}{14}
\bibcite{PhysRevLett.85.2300}{15}
\bibcite{Parlitz2000NonlinearPO}{16}
\bibcite{2000PhRvL..84.1890P}{17}
\bibcite{Xia2006APF}{18}
\bibcite{ENV:ENV2266}{19}
\bibcite{covas2016}{20}
\bibcite{ENV:ENV2456}{21}
\@writefile{toc}{\contentsline {section}{References}{7}}
\bibcite{covaspeixinhojoao}{22}
\bibcite{2017arXiv170805094M}{23}
\bibcite{2017arXiv171100636M}{24}
\bibcite{2017arXiv171110566R}{25}
\bibcite{2017arXiv171110561R}{26}
\bibcite{2017arXiv171009668L}{27}
\bibcite{2018JCoPh.357..125R}{28}
\bibcite{2018arXiv180106637R}{29}
\bibcite{9780521857291}{30}
\bibcite{9780198512905}{31}
\bibcite{1851RSPT..141..123S}{32}
\bibcite{1852RSPT..142..103S}{33}
\bibcite{1979P&SS...27.1001S}{34}
\bibcite{1983SoPh...89..195E}{35}
\bibcite{1965P&SS...13....9P}{36}
\bibcite{2000AdSpR..26...27W}{37}
\bibcite{2003A&AT...22..861B}{38}
\bibcite{2005GeoRL..3221106S}{39}
\bibcite{2005SpWea...3.8C01K}{40}
\bibcite{2006GMS...165..367T}{41}
\bibcite{2006GeoRL..3318101H}{42}
\bibcite{2009SunGe...4...55C}{43}
\bibcite{2011SpWea...9.6001C}{44}
\bibcite{2013EGUGA..1510865W}{45}
\bibcite{2015SpWea..13..524S}{46}
\bibcite{1985PhLA..107..101G}{47}
\bibcite{Waibel:1990:PRU:108235.108263}{48}
\bibcite{luk2000study}{49}
\bibcite{Frank2001}{50}
\bibcite{OH2002249}{51}
\bibcite{1009-1963-12-6-304}{52}
\bibcite{inputlayer}{53}
\bibcite{1981LNM...898..366T}{54}
\bibcite{key1503303m}{55}
\bibcite{1981LNM...898..230M}{56}
\bibcite{1991JSP....65..579S}{57}
\bibcite{Fraser86}{58}
\bibcite{abarbanel1997analysis}{59}
\bibcite{opac-b1092652}{60}
\bibcite{1992PhRvA..45.3403K}{61}
\bibcite{1992PhRvA..45.7058M}{62}
\bibcite{1993RvMP...65.1331A}{63}
\bibcite{1996PhT....49k..86A}{64}
\bibcite{McCulloch1943}{65}
\bibcite{2017arXiv171205293C}{66}
\bibcite{ghaderi2017deepforecast}{67}
\bibcite{annunziato}{68}
\bibcite{Gkana201579}{69}
\bibcite{Zachilas2015}{70}
\bibcite{Sun2010109}{71}
\bibcite{HUANG20108590}{72}
\bibcite{298224}{73}
\bibcite{1998GeoRL..25..457K}{74}
\bibcite{BUHAMRA2003805}{75}
\bibcite{chandra2012cooperative}{76}
\bibcite{DBLP:journals/corr/MaslennikovaB14}{77}
\bibcite{sauter2010spatio}{78}
\bibcite{JiangS11}{79}
\bibcite{1997IJMPC...8.1345K}{80}
\bibcite{Verdes2000}{81}
\bibcite{1996SoPh..168..423F}{82}
\bibcite{2007AdG....10...67L}{83}
\bibcite{Chandra:2012:CCE:2181341.2181747}{84}
\bibcite{raios}{85}
\bibcite{maass2003mathematical}{86}
\bibcite{0305-4470-28-12-012}{87}
\bibcite{1995ApJ...444..916C}{88}
\bibcite{Simon:2007:HDS:1230147.1230294}{89}
\bibcite{articleRagulskis}{90}
\bibcite{10.1007/BFb0006203}{91}
\bibcite{1986Natur.323..533R}{92}
\bibcite{58337}{93}
\bibcite{Wang04imagequality}{94}
\bibcite{2015arXiv150100092D}{95}
\bibcite{2018arXiv180208369Z}{96}
\bibcite{2009ISPM...26...98W}{97}
\bibcite{2012ITIP...21.1488B}{98}
\bibcite{1555956}{99}
\bibcite{2001Chaos..11..404C}{100}
\bibcite{2001cfsm.book.....B}{101}
\bibcite{1990EOSTr..71..677K}{102}
\bibcite{1991PhDT.......158W}{103}
\bibcite{Weigend92HubermanRumelhart}{104}
\bibcite{1993AdSpR..13..447M}{105}
\bibcite{1995JGR...10021735M}{106}
\bibcite{1994VA.....38..351C}{107}
\bibcite{Koskela96timeseries}{108}
\bibcite{1996AnGeo..14...20F}{109}
\bibcite{1996ITNN....7..501P}{110}
\bibcite{1998JGR...10329733C}{111}
\bibcite{1998NewAR..42..343C}{112}
\bibcite{2004SoPh..221..167V}{113}
\bibcite{2001GMS...125..201L}{114}
\bibcite{2002PhRvE..66f6701S}{115}
\bibcite{2004SoPh..224..247M}{116}
\bibcite{2005JASTP..67..595G}{117}
\bibcite{2004SPIE.5497..542A}{118}
\bibcite{2005MmSAI..76.1030Q}{119}
\bibcite{2005SoPh..227..177A}{120}
\bibcite{2006JASTP..68.2061M}{121}
\bibcite{2007SoPh..243..253Q}{122}
\bibcite{2013Ap&SS.344....5A}{123}
\bibcite{xie2006hybrid}{124}
\bibcite{2006SunGe...1a...8M}{125}
\bibcite{2007IJMPC..18.1839E}{126}
\bibcite{1997SPIE.3077..116P}{127}
\bibcite{2006AGUFMSH21A0315L}{128}
\bibcite{2008cosp...37.3467W}{129}
\bibcite{gang2007sunspot}{130}
\bibcite{2009JASTP..71..569U}{131}
\bibcite{2010BAAA...53..241F}{132}
\bibcite{1999BAAA...43...23P}{133}
\bibcite{2011RAA....11..491A}{134}
\bibcite{2010cosp...38.2153A}{135}
\bibcite{2011CRGeo.343..433C}{136}
\bibcite{2012cosp...39.1194M}{137}
\bibcite{park2009prediction}{138}
\bibcite{kim2010sunspot}{139}
\bibcite{moghaddam2013sunspot}{140}
\bibcite{2012EPJP..127...43C}{141}
\bibcite{liu2012sunspot}{142}
\bibcite{DBLP:conf/ijcnn/ParsapoorBS15}{143}
\bibcite{DBLP:conf/aaai/ParsapoorBS15}{144}
\bibcite{1989PThPS..99..263K}{145}
\bibcite{1989JSP....54.1489M}{146}
\bibcite{9780471937418}{147}
\bibcite{articleLorenz96}{148}
\bibcite{1976PThPh..55..356K}{149}
\bibcite{1977AcAau...4.1177S}{150}
\bibcite{Wikle:2015:MPS:3160227.3160234}{151}
\@writefile{toc}{\contentsline {section}{Biographies}{10}}
\@writefile{toc}{\contentsline {subsection}{Eurico Covas}{10}}
\@writefile{toc}{\contentsline {subsection}{Emmanouil Benetos}{10}}
\@writefile{toc}{\contentsline {subsection}{Jane Doe}{10}}
